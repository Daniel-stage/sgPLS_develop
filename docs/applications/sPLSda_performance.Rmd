---
title: "sPLS-DA_performance"
output: html_document
date: "2025-08-01"
---

# Introduction

This page presents an application of the sPLSDA performance assessment. The PLS method is a quite particular method : there are several predictions according to the components number selected in the model. It is the same with sPLSDA. The goal is almost to choose the best number of component in PLS regression in order to compute the best possible predictions. For that, we will use two datasets: 

- one is a dataset with only five predictor variable $X = (X1,X2,X3,X4,X5)$ and two classes.

- the other is a dataset with forty predictor variables $X = (X1,X2,...,X40)$ ans three classes. With $p > n$, this dataset approches realist conditions for PLS training.

To access to predefined functions from sgPLSdevelop package and manipulate these datasets, run these lines :

```{r data, message=FALSE, warning=FALSE}
library(sgPLSdevelop)

data1 <- data.cl.create(p = 5, list = TRUE) # 2 classes by default
data2 <- data.cl.create(n = 30, p = 40, classes = 3, list = TRUE)
```

Now, it's time to train a PLS model for each dataset built.

```{r pls, message=FALSE, warning=FALSE}
ncomp.max <- 5

# First model
X <- data1$X
Y <- as.factor(data1$Y)
model1 <- PLSda(X,Y, ncomp = ncomp.max)

# Second model
X <- data2$X
Y <- as.factor(data2$Y)
model2 <- PLSda(X,Y, ncomp = ncomp.max)
```


# PLS-DA performance assessment by mean error rate by using leave-one-out cross-validation (LOOCV)

### First model 

```{r}
#perf.res1 <- perf.sPLSda(model1)
#h.best <- perf.res1$h.best
#msep.best <- perf.res1$MSEP[h.best]
h.best <- 0
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.

### Second model

```{r}
#perf.res2 <- perf.sPLSda(model2)
#h.best <- perf.res2$h.best
#msep.best <- perf.res2$MSEP[h.best]
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.

# PLS-DA performance assessment by mean error rate by using 10-fold cross-validation

### First model 

```{r}
#perf.res1 <- perf.sPLSda(model1, K = 10)
#h.best <- perf.res1$h.best
#msep.best <- perf.res1$MSEP[h.best]
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.

### Second model 

```{r}
#perf.res2 <- perf.sPLSda(model2, K = 10)
#h.best <- perf.res2$h.best
#msep.best <- perf.res2$MSEP[h.best]
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.

# PLS-DA performance assessment by mean error rate by using 5-fold cross-validation

### First model 

```{r}
#perf.res1 <- perf.sPLSda(model1, K = 5)
#h.best <- perf.res1$h.best
#msep.best <- perf.res1$MSEP[h.best]
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.

### Second model 

```{r}
#perf.res2 <- perf.sPLSda(model2, K = 5)
#h.best <- perf.res2$h.best
#msep.best <- perf.res2$MSEP[h.best]
```

The `perf.PLS` gives us a optimal components number equal to $H =$ `r h.best`, therefore we suggest to select `r h.best` components in our first model.
